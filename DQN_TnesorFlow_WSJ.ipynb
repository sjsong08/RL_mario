{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "(?, 100)\n",
      "(?, 100)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2,3,512,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: main/conv2d/kernel/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@main/conv2d/kernel\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](main/conv2d/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'main/conv2d/kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-d1493b3999ff>\", line 352, in <module>\n    main()\n  File \"<ipython-input-1-d1493b3999ff>\", line 159, in main\n    mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\")\n  File \"/ideaHome/Dropbox/SJ/ML/RL/Mario/dqn_mario/dqn.py\", line 12, in __init__\n    self._build_network()\n  File \"/ideaHome/Dropbox/SJ/ML/RL/Mario/dqn_mario/dqn.py\", line 115, in _build_network\n    VGG_Layer6_1 = tf.layers.conv2d(VGG_Layer5_3, filters=100, kernel_size=[2, 3], strides=[1, 1], padding='VALID')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 619, in conv2d\n    return layer.apply(inputs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 825, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 696, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 144, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable.py\", line 415, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py\", line 472, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 672, in random_uniform\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2,3,512,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: main/conv2d/kernel/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@main/conv2d/kernel\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](main/conv2d/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2,3,512,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: main/conv2d/kernel/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@main/conv2d/kernel\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](main/conv2d/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d1493b3999ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-d1493b3999ff>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mmainDQN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mtargetDQN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0mcopy_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_copy_var_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_scope_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_scope_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2278\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \"\"\"\n\u001b[0;32m-> 2280\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5049\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5050\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5051\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2,3,512,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: main/conv2d/kernel/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@main/conv2d/kernel\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](main/conv2d/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'main/conv2d/kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-d1493b3999ff>\", line 352, in <module>\n    main()\n  File \"<ipython-input-1-d1493b3999ff>\", line 159, in main\n    mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\")\n  File \"/ideaHome/Dropbox/SJ/ML/RL/Mario/dqn_mario/dqn.py\", line 12, in __init__\n    self._build_network()\n  File \"/ideaHome/Dropbox/SJ/ML/RL/Mario/dqn_mario/dqn.py\", line 115, in _build_network\n    VGG_Layer6_1 = tf.layers.conv2d(VGG_Layer5_3, filters=100, kernel_size=[2, 3], strides=[1, 1], padding='VALID')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 619, in conv2d\n    return layer.apply(inputs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 825, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 696, in __call__\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\", line 144, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable.py\", line 415, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py\", line 472, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 672, in random_uniform\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2,3,512,100] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: main/conv2d/kernel/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@main/conv2d/kernel\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](main/conv2d/kernel/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "import ppaquette_gym_super_mario\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from collections import deque\n",
    "from dqn_mario import dqn\n",
    "\n",
    "from random import randint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import gym\n",
    "from gym import wrappers\n",
    "#reward : distance\n",
    "\n",
    "checkpoint_dir = './wonseok_checkpoint/'  #\n",
    "train = True\t\n",
    "retrain = False\n",
    "\n",
    "env = gym.make('ppaquette/SuperMarioBros-1-1-v0')\n",
    "env = wrappers.Monitor(env, 'gym-results', force=True)\n",
    "\n",
    "# Constants defining our neural network\n",
    "\n",
    "input_size = np.array([env.observation_space.shape[0], env.observation_space.shape[1], 15]) #width*height*3ch\n",
    "output_size = 13 #up, down, left, right, run, jump\n",
    "\n",
    "dis = 0.9\n",
    "REPLAY_MEMORY = 20000\n",
    "\n",
    "# Minibatch works better\n",
    "\n",
    "def ddqn_replay_train(mainDQN, targetDQN, train_batch, l_rate):\n",
    "    '''\n",
    "    Double DQN implementation\n",
    "    :param mainDQN: main DQN\n",
    "    :param targetDQN: target DQN\n",
    "    :param train_batch: minibatch for train\n",
    "    :return: loss\n",
    "    '''\n",
    "    #x_stack = np.empty(0).reshape(0, mainDQN.input_size)\n",
    "    x_stack = np.empty(0).reshape(0, mainDQN.input_size[0]*mainDQN.input_size[1]*mainDQN.input_size[2])\n",
    "    y_stack = np.empty(0).reshape(0, mainDQN.output_size)\n",
    "    action_stack = np.empty(0).reshape(0, 60)\n",
    "\n",
    "    # Get stored information from the buffer\n",
    "    for state, action_seq, action_next_seq, action, reward, next_state, done in train_batch:\n",
    "        Q = mainDQN.predict(state, action_seq)\n",
    "\n",
    "        # terminal?\n",
    "\n",
    "        if done:\n",
    "            Q[0, action] = reward\n",
    "        else:\n",
    "\n",
    "            Q[0, action] = reward + dis * targetDQN.predict(next_state, action_next_seq)[0, np.argmax(mainDQN.predict(next_state, action_next_seq))]\n",
    "\n",
    "\n",
    "        if state is None:\n",
    "            print(\"None State, \", action, \" , \", reward, \" , \", next_state, \" , \", done)\n",
    "        else:\n",
    "            y_stack = np.vstack([y_stack, Q])\n",
    "            x_stack = np.vstack([x_stack, state.reshape(-1, mainDQN.input_size[0]*mainDQN.input_size[1]*mainDQN.input_size[2])])\n",
    "            action_stack = np.vstack([action_stack, np.reshape(action_seq, (-1, 60))])\n",
    "            #x_stack = np.vstack([x_stack, state.reshape(-1, mainDQN.input_size)])\n",
    "\n",
    "    # Train our network using target and predicted Q values on each episode\n",
    "    return mainDQN.update(x_stack, y_stack, action_stack, l_rate = l_rate)\n",
    "\n",
    "def get_copy_var_ops(*,dest_scope_name=\"target\", src_scope_name=\"main\"):\n",
    "\n",
    "    # Copy variables src_scope to dest_scope\n",
    "    op_holder = []\n",
    "\n",
    "    src_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "\n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "\n",
    "    return op_holder\n",
    "\n",
    "def bot_play(mainDQN, env=env):\n",
    "    # See our trained network in action\n",
    "    state = env.reset()\n",
    "    reward_sum = 0\n",
    "    while True:\n",
    "\n",
    "        if state is None or state.size == 1:\n",
    "            output = randint(0, output_size - 1)\n",
    "            action = OutputToAction3(output)\n",
    "            print(\"random action:\", output)\n",
    "        else:\n",
    "            output = np.argmax(mainDQN.predict(state))\n",
    "            action = OutputToAction3(output)\n",
    "            print(\"predicted action:\", output)\n",
    "        for n in range(len(action)):\n",
    "            state, reward, done, info = env.step(action[n])\n",
    "            if done == True:\n",
    "                break\n",
    "        reward_sum += reward\n",
    "        if done:\n",
    "            print(\"Total score: {}\".format(reward_sum))\n",
    "            break\n",
    "\n",
    "\n",
    "def OutputToAction3(output): #A:jump B:run\n",
    "\n",
    "    if output == 0:\n",
    "        action = np.array([[0, 0, 0, 0, 0, 0]]*2)  # NOOP\n",
    "    elif output == 1:\n",
    "        action = np.array([[1, 0, 0, 0, 0, 0]]*2)  # Up\n",
    "    elif output == 2:\n",
    "        action = np.array([[0, 0, 1, 0, 0, 0]]*2)  # Down\n",
    "    elif output == 3:\n",
    "        action = np.array([[0, 1, 0, 0, 0, 0]]*2)  # Left\n",
    "    elif output == 4:\n",
    "        action = np.array([[0, 1, 0, 0, 1, 0]]*2)  # Left + A (short jump)\n",
    "    elif output == 5:\n",
    "        action = np.array([[0, 1, 0, 0, 0, 1]]*2)  # Left + B\n",
    "    elif output == 6:\n",
    "        action = np.array([[0, 1, 0, 0, 1, 1]]*2)  # Left + A + B (short jump)\n",
    "    elif output == 7:\n",
    "        action = np.array([[0, 0, 0, 1, 0, 0]]*2)  # Right\n",
    "    elif output == 8:\n",
    "        action = np.array([[0, 0, 0, 1, 1, 0]]*2)  # Right + A (short jump)\n",
    "    elif output == 9:\n",
    "        action = np.array([[0, 0, 0, 1, 0, 1]]*2)  # Right + B\n",
    "    elif output == 10:\n",
    "        action = np.array([[0, 0, 0, 1, 1, 1]]*2)  # Right + A + B (short jump)\n",
    "    elif output == 11:\n",
    "        action = np.array([[0, 0, 0, 0, 1, 0]]*2)  # A (short jump)\n",
    "    else:\n",
    "        action = np.array([[0, 0, 0, 0, 1, 1]]*2) # A + B (short jump)\n",
    "\n",
    "    return action\n",
    "\n",
    "def main():\n",
    "    if train == True:\n",
    "        init_episode = 1\n",
    "        max_episodes = 10000\n",
    "        # store the previous observations in replay memory\n",
    "        replay_buffer = deque()\n",
    "        state_buffer = deque()\n",
    "        next_state_buffer = deque()\n",
    "        output_buffer = deque()\n",
    "\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        # config.log_device_placement = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\")\n",
    "            targetDQN = dqn.DQN(sess, input_size, output_size, name=\"target\")\n",
    "            tf.global_variables_initializer().run()\n",
    "            copy_ops = get_copy_var_ops(dest_scope_name=\"target\", src_scope_name=\"main\")\n",
    "            sess.run(copy_ops)\n",
    "\n",
    "            if retrain == True:\n",
    "                saver = tf.train.Saver()\n",
    "                saver.restore(sess, checkpoint_dir + 'model_notime.ckpt')\n",
    "                print(\"restored!\")\n",
    "\n",
    "            # initial copy q_net -> target_net\n",
    "\n",
    "\n",
    "            for episode in range(init_episode, max_episodes):\n",
    "                #e = 1. / ((episode // 100)/10 + 1)\n",
    "                e = 1.0 / (episode/500 + 1)\n",
    "                print(\"episode:\", episode, \", e:\", e)\n",
    "                done = False\n",
    "                step_count = 0\n",
    "                state = env.reset()\n",
    "                score = 0\n",
    "                distance = 0\n",
    "                prev_output = -1\n",
    "                repeat =0\n",
    "\n",
    "                while not done:\n",
    "                    #if np.random.rand(1) < e:\n",
    "                    if np.random.rand(1) < e or state is None or state.size == 1 or step_count<=10:\n",
    "                    #if (np.random.rand(1) < e and episode%2==0) or step_count <= 10:\n",
    "\n",
    "                        output = randint(0, output_size-1)\n",
    "\n",
    "                        if output>=3 and output<=6:\n",
    "                            temp = np.random.rand(1)\n",
    "                            if temp>(episode/100):\n",
    "                                pass\n",
    "                                #output = 10\n",
    "\n",
    "                        action = OutputToAction3(output)\n",
    "                        print(\"random action:\", output)\n",
    "\n",
    "                    else:\n",
    "                        # Choose an action by greedily from the Q-network\n",
    "                        predicted = mainDQN.predict(acc_state, output_seq)\n",
    "                        output = np.argmax(predicted)\n",
    "                        action = OutputToAction3(output)\n",
    "\n",
    "                        print(\"output:\", output, \"predicted:\", predicted)\n",
    "                        #print(\"output:\", output)\n",
    "\n",
    "                    # Get new state and reward from environment\n",
    "                    for n in range(len(action)):\n",
    "                        next_state, reward, done, info = env.step(action[n])\n",
    "                        if done == True:\n",
    "                            print(\"%dth:\", n)\n",
    "                            break\n",
    "                    print(\"dms~~\",reward)\n",
    "                    state_buffer.append(next_state)\n",
    "                    #next_state_buffer.append(next_state)\n",
    "\n",
    "                    output_buffer.append(action)\n",
    "\n",
    "                    prev_distance = distance\n",
    "                    distance = info['distance']\n",
    "                    got_distance = distance-prev_distance\n",
    "\n",
    "                    past_score = score\n",
    "                    score = info['score']\n",
    "                    got_score = score-past_score\n",
    "\n",
    "                    time = info['time']\n",
    "                   \n",
    "                    reward = got_score/50 + got_distance/30\n",
    "                    \n",
    "                    if reward>0:\n",
    "                        print(\"reward:\", reward)\n",
    "\n",
    "\n",
    "                    if done: # Penalty\n",
    "                        #time = info['time']\n",
    "\n",
    "                        \n",
    "\n",
    "                        reward += -1.0\n",
    "\n",
    "                        if distance>=3000:\n",
    "                            reward = 1\n",
    "                        #reward += distance / 1000\n",
    "                        print(\"last reward:\", reward)\n",
    "\n",
    "\n",
    "\n",
    "                    # Save the experience to our buffer\n",
    "                    #print(\"state:\", np.shape(state))\n",
    "                    if step_count>=10:\n",
    "                        acc_state = [state_buffer[-2-k] for k in range(5)]\n",
    "\n",
    "                        state_buffer.popleft()\n",
    "                        acc_state = np.reshape(acc_state, (input_size[0], input_size[1], input_size[2]))\n",
    "\n",
    "                        acc_next_state = [state_buffer[-1-k] for k in range(5)]\n",
    "\n",
    "\n",
    "                        acc_next_state = np.reshape(acc_next_state, (input_size[0], input_size[1], input_size[2]))\n",
    "\n",
    "                        output_seq = [output_buffer[-2-k] for k in range(5)]\n",
    "                        output_next_seq = [output_buffer[-1-k] for k in range(5)]\n",
    "                        output_buffer.popleft()\n",
    "\n",
    "                        replay_buffer.append((acc_state, output_seq, output_next_seq, output, reward, acc_next_state, done))\n",
    "                        if replay_buffer[-1][6]: #if done==true?\n",
    "                            for k in range(1, 5):\n",
    "                                replay_buffer[-1 - k] = tuple(\n",
    "                                    replay_buffer[-1 - k][0:4] + (-pow(0.9, k),) + replay_buffer[-1 - k][5:])\n",
    "                        if replay_buffer[-1][4] >= 2.0 and replay_buffer[-1][6] == False:\n",
    "                            for k in range(1, 5):\n",
    "                                replay_buffer[-1 - k] = tuple(\n",
    "                                    replay_buffer[-1 - k][0:4] + (pow(0.9, k),) + replay_buffer[-1 - k][5:])\n",
    "\n",
    "                        #replay_buffer.append((state, action, reward, next_state, done))\n",
    "                        if len(replay_buffer) > REPLAY_MEMORY:\n",
    "                            replay_buffer.popleft()\n",
    "                        acc_state = acc_next_state\n",
    "\n",
    "\n",
    "\n",
    "                    state = next_state\n",
    "                    step_count += 1\n",
    "                    if step_count > 100000:   # Good enough. Let's move on\n",
    "                        break\n",
    "\n",
    "                    #if step_count==1:\n",
    "                    #    replay_buffer.pop()\n",
    "\n",
    "\n",
    "\n",
    "                print(\"Episode: {} steps: {}\".format(episode, step_count))\n",
    "                if step_count > 100000:\n",
    "                    pass\n",
    "                    # break\n",
    "\n",
    "                if (episode+1) % 1 == 0: # train every 10 episode\n",
    "                    # Get a random batch of experiences\n",
    "                    for _ in range(50):\n",
    "                        # Minibatch works better\n",
    "                        if len(replay_buffer) >= 10:\n",
    "\n",
    "                            sample_idx = random.sample(range(0, len(replay_buffer)), 10)\n",
    "\n",
    "                            minibatch2 = []\n",
    "                            for i in sample_idx:\n",
    "\n",
    "                                minibatch2.append(replay_buffer[i])\n",
    "\n",
    "                            l_rate =(1e-5 -1e-4)*(1/max_episodes)*episode + 1e-4\n",
    "                            loss, _ = ddqn_replay_train(mainDQN, targetDQN, minibatch2, l_rate=l_rate)\n",
    "\n",
    "                            print(\"Loss: \", loss, \"l_rate:\", l_rate)\n",
    "                if (episode+1) % 2 == 0: # train every 10 episode\n",
    "                    sess.run(copy_ops)\n",
    "                    print(\"weights copied\")\n",
    "\n",
    "                if (episode + 1) % 100 == 0:  # train every 10 episode\n",
    "                    saver = tf.train.Saver()\n",
    "                    saver.save(sess, checkpoint_dir + 'model_notime.ckpt')\n",
    "                    print(\"model saved\")\n",
    "                    env.reset()\n",
    "\n",
    "            # See our trained bot in action\n",
    "            env2 = wrappers.Monitor(env, 'gym-results', force=True)\n",
    "\n",
    "            for i in range(200):\n",
    "                bot_play(mainDQN, env=env2)\n",
    "\n",
    "            env2.close()\n",
    "\n",
    "    else:\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        # config.log_device_placement = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\")\n",
    "            targetDQN = dqn.DQN(sess, input_size, output_size, name=\"target\")\n",
    "            tf.global_variables_initializer().run()\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, checkpoint_dir + 'model_notime.ckpt')\n",
    "            for i in range(200):\n",
    "                bot_play(mainDQN, env=env)\n",
    "\n",
    "            env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
